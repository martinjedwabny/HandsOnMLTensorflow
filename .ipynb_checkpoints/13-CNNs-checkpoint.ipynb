{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intro\n",
    "\n",
    "* CNNs are best for visual perception, voice recognition and natural language processing (NLP).\n",
    "* In contrast to fully connected DNN (which scale badly for millions of features), each neuron is only partially connected to the next layer.\n",
    "* Neurons in the first convolutional layer are not connected to every single pixel in the input image, but only to pixels in their receptive fields. In turn, each neuron in the second convolutional layer is connected only to neurons located within a small rectangle in the first layer.\n",
    "* This idea is based on the mechanics of how the visual cortex works i.e. neurons build upon only a subset of the previous layer (a local receptive field) to process increasingly complex patterns in order to understand images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "\n",
    "* A neuron located in row $i$, column $j$ of a layer is connected to the neurons in the previous layer located in rows $i$ to $i + f_h – 1$, columns $j$ to $j + f_w – 1$. \n",
    "* $f_h$ and $f_w$ are the height and width of the receptive field. \n",
    "* The distance between two consecutive receptive fields is called the $stride$. \n",
    "* To maintain neuron size between layers, it is common to add zeros around the inputs. This is called zero padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual representation\n",
    "\n",
    "<img src=\"files/conv_vis_rep.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define layers\n",
    "def conv_layer(filters=32, activation_fn=tf.nn.relu):\n",
    "    return lambda layer : tf.layers.conv2d(\n",
    "        inputs=layer,\n",
    "        filters=filters,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"SAME\",\n",
    "        activation=activation_fn)\n",
    "\n",
    "def relu_layer():\n",
    "    return lambda layer : tf.nn.relu(layer)\n",
    "\n",
    "def pool_layer():\n",
    "    return lambda layer : tf.nn.max_pool(\n",
    "        layer, \n",
    "        ksize=[1,2,2,1], \n",
    "        strides=[1,2,2,1],\n",
    "        padding=\"VALID\")\n",
    "\n",
    "def fully_connected_layer(n_inputs, n_outputs, activation_fn=tf.nn.relu):\n",
    "    return lambda layer : tf.contrib.layers.fully_connected(\n",
    "        tf.reshape(layer, [-1, n_inputs]), \n",
    "        n_outputs, \n",
    "        activation_fn=activation_fn)\n",
    "\n",
    "def softmax_layer():\n",
    "    return lambda layer : tf.nn.softmax(layer)\n",
    "\n",
    "# Create architecture\n",
    "def create_nn(X,layer_fs):\n",
    "    for layer_f in layer_fs:\n",
    "        X = layer_f(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Load sample images \n",
    "# cifar10 (162.17 MiB) \n",
    "# 60000 32x32 colour images in 10 classes, with 6000 images per class\n",
    "dataset = tfds.load(name=\"cifar10\", split=tfds.Split.TRAIN).map(\n",
    "    lambda elem : {\"image\": tf.cast(elem['image'], tf.float64), \n",
    "                   \"label\": elem['label']})\n",
    "\n",
    "# Load shapes\n",
    "height, width, channels = dataset.output_shapes['image']\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 872.2247304916382\n",
      "1 228.6411497592926\n",
      "2 222.81011629104614\n",
      "3 213.71810901165009\n",
      "4 202.59857857227325\n",
      "5 191.03315341472626\n",
      "6 181.55472087860107\n",
      "7 171.2621158361435\n",
      "8 161.51873195171356\n",
      "9 153.3797744512558\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./c13_1.ckpt\"\n",
    "\n",
    "# Training Hyperparameters\n",
    "num_epochs = 10\n",
    "num_batches = 64\n",
    "num_dataset = 6400\n",
    "\n",
    "# Dataset\n",
    "train_dataset = dataset.map(\n",
    "    lambda elem : {\"image\": tf.to_float(elem['image']), \n",
    "                   \"label\": elem['label']})\n",
    "train_dataset = train_dataset.take(num_dataset)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
    "train_dataset = train_dataset.batch(num_batches)\n",
    "iterator = train_dataset.make_initializable_iterator()\n",
    "elem = iterator.get_next()\n",
    "X, y = elem['image'], elem['label']\n",
    "\n",
    "# Create CNN layers\n",
    "output = create_nn(X, [conv_layer(),\n",
    "                       pool_layer(),\n",
    "                       fully_connected_layer(num_batches**2*2, n_outputs), \n",
    "                       fully_connected_layer(n_outputs, n_outputs)\n",
    "                      ])\n",
    "\n",
    "# Loss and training operation\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=output)\n",
    "training_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "predictions = {\n",
    "    \"classes\": tf.argmax(input=output, axis=1),\n",
    "    \"probabilities\": tf.nn.softmax(output, name=\"softmax_tensor\"),\n",
    "    \"loss\": loss\n",
    "}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_sum = 0\n",
    "        sess.run(iterator.initializer)\n",
    "        try:\n",
    "            while True:\n",
    "                _, result = sess.run([training_op, predictions])\n",
    "                loss_sum += result[\"loss\"]\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print(epoch, loss_sum)\n",
    "    tf.train.Saver().save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./c13_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0526 23:37:14.796082 140734930376128 saver.py:1270] Restoring parameters from ./c13_1.ckpt\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_target = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.train.Saver().restore(sess, save_path)\n",
    "    sess.run(iterator.initializer)\n",
    "    try:\n",
    "        while True:\n",
    "            y_pred_batch, y_target_batch = sess.run([predictions[\"classes\"], y])\n",
    "            y_pred.append(y_pred_batch)\n",
    "            y_target.append(y_target_batch)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target    [8 6 6 8 6 2 3 6 9 8 7 1 3 1 2 1 0 7 2 3 4 2 7 2 8 0 2 3 0 9]\n",
      "Predicted [8 6 3 9 6 6 7 5 9 9 7 5 2 4 0 8 9 7 7 6 6 9 7 5 0 0 2 6 8 9]\n"
     ]
    }
   ],
   "source": [
    "y_target_flat = np.array(y_target).flatten()\n",
    "y_pred_flat = np.array(y_pred).flatten()\n",
    "\n",
    "print(\"Target   \", y_target_flat[:30])\n",
    "print(\"Predicted\", y_pred_flat[:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
